= Face Toolbox Overview
:showtitle:
:revdate: 2020-03-25

== Overview
There are two categories of face artefact that can be used for presentation attack. The first one is two-dimensional (2D) face artefact such as a printed photo of a target user and the second is, for example, a face mask that mimics three-dimensional (3D) geometry of a user’s face. This toolbox describes 2D and 3D face artefacts separately that the evaluator shall create for the PAD testing.

There are also two types of face biometric verification method, 2D or 3D image-based methods. The 2D image-based method captures a two-dimensional face image by a sensor using visible light to recognize a person. The 3D image-based method creates three-dimensional model of the human face using a 3D scanner such as a depth camera.

The evaluator shall refer to this toolbox for the creation of both 2D and 3D face artefacts. However, depending on the type of sensor being used for verification, not all species types may be required as part of the testing. The Face Verification List specifies the types of species that should be created based on the sensor being evaluated.

== Face Presentation Attacks
=== 2D Attacks
There are many research papers that study face presentation attack and researchers create 2D face artefacts through the following process.

. Capture face images of a target user using a camera

. Print or display captured image on a paper or screen that is called a 2D face artefact

. Present a 2D face artefact to the TOE

Presentation attack with 2D face artefacts can be categorized into the following three types based on tools or materials used.

* printed photo attack
+
An attacker attempts to spoof the TOE using a captured face image printed on a paper

* digital photo attack
+
An attacker attempts to spoof the TOE using a captured face image displayed on a screen

* replay video attack
+
An attacker attempts to spoof the TOE using a recorded face video replayed on a screen

=== 3D Attacks
There are three categories of 3D face artefacts or masks studied in existing research papers. Some papers report successful presentation attacks using target user’s face with some artefacts (e.g. putting special glasses above the sleeping target user’s face to bypass the attention detection mechanism) however, this toolbox doesn’t consider such attack scenarios because attack potential required to exploit these scenarios is clearly beyond the Basic attack potential.

- Printed Face mask
+
Printed photo is bent and worn as a face mask to create the illusion of 3D in a real face.

- 3D face mask or head from 2D face image
+
Predict the 3D features of the face from 2D images and create a 3D face mask or head from the predicted 3D face image.

- 3D face mask or head from 3D face image
+
Get a 3D face image through a 3D scan of the face or using molding material and create a 3D face mask or head from the actual 3D image of a target user’s face.

The last category, 3D face mask or head from 3D face image, is out of scope of this toolbox because it’s beyond the Basic attack potential. As described in <<BIOSD>>, the attack potential shall be rated as follows.

-	*Elapsed time* for *Identification*
+
*⇐ one week* (1)

-	*Window of Opportunity (Access to TOE)* for *Exploitation*
+
*Moderate* (4)

In addition to them, following factors for creating a 3D face mask or head from 3D face image should be rated as follows.

-	*Window of Opportunity (Access to Biometric Characteristics)*
+
*Moderate* (4), because 3D scan of the face or using molding material requires direct contact with a target user

-	*Expertise* for *Identification*
+
*Proficient* (2), because using a 3D scanner and 3D printer or using molding material and resin for creating sufficient quality of 3D face mask or head requires some level of knowledge and experiences that the Layman doesn’t has.

In total, the attack potential for 3D face mask or head from 3D face image is at least 11, that is beyond the Basic attack potential (10). This is the reason why this toolbox excludes this type of artefacts. However, both Printed Face mask and 3D face mask or head 
from 2D face image is within the scope of the Basic attack potential because only 2D images of target face is required to create 
both face artefacts, so *Window of Opportunity (Access to Biometric Characteristics)* should be rated as *Immediate* (0).

3D face presentation attack can be conducted through the following process using 3D face mask or head described above.

. Capture face images of a target user using a camera

*Printed Face mask*

[start=2]
. Print captured image on a paper

. Wear a face mask and present it to the TOE

*3D face mask or head from 2D face image*

[start=2]
. Reconstruct the 3D face from 2D face images and create a 3D face mask or head

. Wear a face mask and present it to the TOE or present the 3D head to the TOE

== Face Presentation Attack Detection
=== 2D Detection
Images captured by the TOE from the 2D face artefacts may visually look very similar to the images captured from a real human, however, they are not exactly the same. For example, printed or displayed images on the paper or screen reflect light in different ways because a human is a complex non-rigid 3D object, whereas the photo or screen can be seen as a planar rigid object. The surface properties of real faces and face artefacts, e.g. pigments, are also different. In addition, face artefacts may contain moir ́e patterns that are an undesired aliasing of images produced during various image display and image acquisition processes. The TOE can detect such differences between images taken from real human and artefacts to detect and prevent the presentation attacks.

=== 3D Detection
The 3D face mask or head contains the quality defect that results in the appearance difference from a genuine face. For example, the skin texture and detailed facial structures in the mask or head have perceivable differences compared to those in real faces. The 3D face mask or head also lacks the facial motion such as facial expression changes, eye blinks and mouth movements because it is made of hard materials. Several PAD methods that utilize such cues have been studied and reported by researchers. Other PAD methods utilize liveness cues such as thermal signatures, gaze information, pulse or heartbeat signals to detect a 3D face mask or head. However, normally such design information of the PAD is not available to the evaluator and the TOE must be tested in black box manner.

== Common Test Protocol
Face PAD testing can be done in a variety of ways. The evaluator can use different type of cameras under different illumination to capture face images of test users to create face artefacts. The evaluator can also present these artefacts under different condition. It’s not possible to cover all such possible test scenarios and this toolbox defines the common test protocol to maintain consistency among different PAD testing but also enable to conduct the testing efficiently referring research papers. The evaluator shall follow the test protocols describe below, in addition to guidance provided in Toolbox Overview to conduct the PAD testing.

The tools and media for the creation of artefacts are defined for all tests in the Face Toolbox Inventory. Each attack specifies which tools and media are to be used in the creation of artefacts for that test.

=== Initial Preparation - All Artefacts

. Enrollment
.. The evaluator shall turn on the face unlock and enroll the test users following instructions provided by the AGD guidance (e.g. test users should not wear glasses, hat, or heavy make-up during the enrolment if the guidance instructs not to do so).
.. The evaluator shall enroll test users’ expressionless frontal faces under the controlled environment where the background of the scene is uniform, the light in the room is switched on and the window blinds are down (direct external lighting is blocked). 

. Face image capture
.. The evaluator shall capture face images right after the enrolment of test users under the same condition to reduce the possibility that the artefacts are rejected because of the difference of illumination, background scene and expression.
.. The evaluator shall capture test users’ face images by normal and high quality cameras for printed and digital photo attack. The evaluator shall also record video of the user's face for ten seconds for reply video attack. 

=== 2D Artefacts - Photos and Video
[start=3]
. Artefact creation
.. The evaluator shall print face images for printed photo attack, display them on a screen for digital photo attack and replay them on a screen for replay video attack. Size of face images on artefacts shall be same as the test user’s face.

. Artefact presentation
.. The evaluator shall present artefacts to the TOE under the same controlled environment as used during enrollment.
.. The evaluator shall adjust the distance between artefacts and the TOE so that the TOE can’t see the edge of artefacts.
.. The evaluator shall present artefacts in a way to minimize the reflection from ambient lighting.
.. The evaluator shall present artefacts by hand for printed and digital photo attack to introduce some noticeable motion and by tripod for replay video attack.

=== 3D Artefacts - Worn Photo Face Mask
[start=3]
. Artefact creation
.. The evaluator shall print face images for printed photo attack, display them on a screen for digital photo attack and replay them on a screen for replay video attack. Size of face images on artefacts shall be same as the test user’s face.

. Artefact presentation
.. The evaluator shall bend and wear the Printed Face mask using tape or paste and present it to the TOE under the same controlled environment.
.. The evaluator shall present a Printed Face mask in a way to minimize the reflection from ambient lighting.

=== 3D Artefacts - 3D Face Mask or Head from 2D Face Image(s)
[start=3]
. Artefact creation
.. The evaluator shall reconstruct a 3D face from captured 2D face image(s). 
.. The evaluator shall create a 3D face mask or head from the 3D image. Size of face mask or head shall be same as the test user’s face.

. Artefact presentation
.. The evaluator shall wear the 3D face mask and present it to the TOE or present the 3D head to the TOE under the same controlled environment.
.. The evaluator shall present the 3D face mask or head in a way to minimize the reflection from ambient lighting.

== Requirements for Tools
The evaluator needs to use several tools, such as cameras, screens, printers and media that meet the specifications of the tools as this impacts the clarity or sharpness of face artefacts. For example, the quality of digital photo depends on the screen resolution. If the screen is 4K that refers to a horizontal screen resolution in the order of 4,000 pixels, and it can provide the finest clarity and detail of the face image.

This toolbox defines two level of tools, normal and high quality (though not all tools have both levels), to cover variety of tools to conduct the PAD testing efficiently. 

Normal quality tools are inexpensive, and anyone can use them easily to capture and upload face images to social media. The attacker can also create face artefacts with such uploaded face images without any difficulty. Presentation attacks using uploaded face images is very easy and detail attack method is published on the Internet, so the evaluator shall try this type of artefacts first. 

High quality tools have better performance (e.g. higher resolution) than normal quality tools and should be the latest tools (i.e. released at least within one year from the date of PAD testing). Those tools may be expensive but can be rented at an affordable cost. The reason why such tools should be used is that the PAD algorithm normally shows good performance for artefacts used to train the algorithm, however less performance for ones the algorithm has never seen before. Also, attackers may try to create high-quality artifacts to maximize the chance of successful attacks. 

For 3D printed masks or heads, if the evaluator outsources the artefact from a third party, the evaluator shall follow the instructions from the third party when capturing photos (e.g. lighting condition) and provide only a maximum of three photos to them.

The evaluator shall create such artefacts that can most likely bypass the PAD using the latest tools.

== Test Items
The evaluator shall create artefacts defined in all test items listed in the Face Verification List. The Face Verification List specifies the species types that must be created based on the type of biometric sensor.

PAD Toolbox Overview defines required number of attempts for the independent testing and maximum timeframe for both independent and penetration testing.

== Pass/Fail Criteria
If Pass/Fail Criteria is defined in the test items the evaluator shall follow them, otherwise follow criteria defined in BIOSD and PAD Toolbox Overview.

== Reference Information 
The Face Toolbox was created based on research papers listed in Face Toolbox References. The evaluator should read them before conducting the PAD testing because they include more detailed information about PAD test methods.
